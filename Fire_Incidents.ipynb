{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d80ec5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependancies\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "from datetime import datetime\n",
    "from shapely.geometry import shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0bd94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toronto Open Data is stored in a CKAN instance. It's APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\"\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = { \"id\": \"fire-station-locations\"}\n",
    "package = requests.get(url, params = params).json()\n",
    "\n",
    "# To get resource data:\n",
    "for idx, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "    \n",
    "    # for datastore_active resources:\n",
    "    if resource[\"datastore_active\"]:\n",
    "        \n",
    "        # To get all records in CSV format:\n",
    "        url = base_url + \"/datastore/dump/\" + resource[\"id\"]\n",
    "        resource_dump_data = requests.get(url).text\n",
    "\n",
    "        # To selectively pull records and attribute-level metadata:\n",
    "        url = base_url + \"/api/3/action/datastore_search\"\n",
    "        p = { \"id\": resource[\"id\"] }\n",
    "        resource_search_data = requests.get(url, params = p).json()[\"result\"]\n",
    "           \n",
    "        # This API call has many parameters. They're documented here:\n",
    "        # https://docs.ckan.org/en/latest/maintaining/datastore.html\n",
    "\n",
    "    # To get metadata for non datastore_active resources:\n",
    "    if not resource[\"datastore_active\"]:\n",
    "        url = base_url + \"/api/3/action/resource_show?id=\" + resource[\"id\"]\n",
    "        resource_metadata = requests.get(url).json()\n",
    "\n",
    "# Assuming resource_search_data is a dictionary\n",
    "\n",
    "df_firestation = pd.DataFrame(resource_search_data['records'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9e6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toronto Open Data is stored in a CKAN instance. It's APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\"\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = { \"id\": \"fire-incidents\"}\n",
    "package = requests.get(url, params = params).json()\n",
    "\n",
    "# To get resource data:\n",
    "for idx, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "    \n",
    "    # for datastore_active resources:\n",
    "    if resource[\"datastore_active\"]:\n",
    "        \n",
    "        # To get all records in CSV format:\n",
    "        url = base_url + \"/datastore/dump/\" + resource[\"id\"]\n",
    "        resource_dump_data = requests.get(url).text\n",
    "\n",
    "        # To selectively pull records and attribute-level metadata:\n",
    "        url = base_url + \"/api/3/action/datastore_search\"\n",
    "        p = { \"id\": resource[\"id\"] }\n",
    "        resource_search_data = requests.get(url, params = p).json()[\"result\"]\n",
    "        \n",
    "        total_rows = resource_search_data['total']\n",
    "        limit = 100  # Number of rows to retrieve per request\n",
    "\n",
    "        # List to hold all the records\n",
    "        all_records = []\n",
    "\n",
    "        # Calculate the number of requests needed based on total rows and limit\n",
    "        num_requests = (total_rows // limit) + 1\n",
    "\n",
    "        #Loop through the requests\n",
    "        for i in range(num_requests):\n",
    "            offset = i * limit\n",
    "            # Make the API request with the appropriate offset\n",
    "            p = {\"id\": resource[\"id\"], \"limit\": limit, \"offset\": offset}\n",
    "            url = base_url + \"/api/3/action/datastore_search\"\n",
    "            response = requests.get(url, params=p).json()[\"result\"]\n",
    "\n",
    "            # Append the records to the list\n",
    "            all_records.extend(response[\"records\"])\n",
    "        \n",
    "#Convert the list of records to a DataFrame\n",
    "df_fireincidents = pd.DataFrame(all_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b481759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toronto Open Data is stored in a CKAN instance. It's APIs are documented here:\n",
    "# https://docs.ckan.org/en/latest/api/\n",
    "\n",
    "# To hit our API, you'll be making requests to:\n",
    "base_url = \"https://ckan0.cf.opendata.inter.prod-toronto.ca\"\n",
    "\n",
    "# Datasets are called \"packages\". Each package can contain many \"resources\"\n",
    "# To retrieve the metadata for this package and its resources, use the package name in this page's URL:\n",
    "url = base_url + \"/api/3/action/package_show\"\n",
    "params = { \"id\": \"neighbourhoods\"}\n",
    "package = requests.get(url, params = params).json()\n",
    "\n",
    "# To get resource data:\n",
    "for idx, resource in enumerate(package[\"result\"][\"resources\"]):\n",
    "    # for datastore_active resources:\n",
    "    if resource[\"datastore_active\"]:\n",
    "        \n",
    "        # To get all records in CSV format:\n",
    "        url = base_url + \"/datastore/dump/\" + resource[\"id\"]\n",
    "        resource_dump_data = requests.get(url).text\n",
    "           \n",
    "\n",
    "        # To selectively pull records and attribute-level metadata:\n",
    "        url = base_url + \"/api/3/action/datastore_search\"\n",
    "        p = { \"id\": resource[\"id\"] }\n",
    "        resource_search_data = requests.get(url, params = p).json()[\"result\"]\n",
    "           \n",
    "        total_rows = resource_search_data['total']\n",
    "        limit = 100  # Number of rows to retrieve per request\n",
    "\n",
    "        # List to hold all the records\n",
    "        all_records = []\n",
    "\n",
    "        # Calculate the number of requests needed based on total rows and limit\n",
    "        num_requests = (total_rows // limit) + 1\n",
    "\n",
    "        #Loop through the requests\n",
    "        for i in range(num_requests):\n",
    "            offset = i * limit\n",
    "            # Make the API request with the appropriate offset\n",
    "            p = {\"id\": resource[\"id\"], \"limit\": limit, \"offset\": offset}\n",
    "            url = base_url + \"/api/3/action/datastore_search\"\n",
    "            response = requests.get(url, params=p).json()[\"result\"]\n",
    "\n",
    "            # Append the records to the list\n",
    "            all_records.extend(response[\"records\"])\n",
    "\n",
    "            \n",
    "#Save the data to DF\n",
    "df_neighborhoods = pd.DataFrame(all_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eebf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check DataType\n",
    "\n",
    "df_neighborhoods.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b781b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check DataType\n",
    "\n",
    "df_fireincidents.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polygon geometry to its correct format\n",
    "\n",
    "df_neighborhoods['geometry'] = df_neighborhoods['geometry'].apply(lambda x: shape(json.loads(x)))\n",
    "df_neighborhoods['geometry'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a91afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values in the dataframe\n",
    "\n",
    "df_fireincidents.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e325a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnesscary columns and fill null values\n",
    "\n",
    "columnstokeep = []\n",
    "for x in df_fireincidents:\n",
    "    if (df_fireincidents[x].isna().sum()<len(df_fireincidents)*.3):\n",
    "        columnstokeep.append(x)\n",
    "    if (df_fireincidents[x].dtypes =='object'):\n",
    "        df_fireincidents[x].fillna('Unknown',inplace = True)\n",
    "    \n",
    "columnstokeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values in this column with default value (0)\n",
    "\n",
    "df_fireincidents['Estimated_Dollar_Loss'].fillna(0, inplace = True)\n",
    "\n",
    "# Trim existing dataframe\n",
    "\n",
    "df_new = df_fireincidents[columnstokeep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa30a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check null values in the dataframe\n",
    "\n",
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7126d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty string values with NAN\n",
    "\n",
    "df_new.replace(\"\",np.nan)\n",
    "\n",
    "# Drop rows with null value\n",
    "\n",
    "df_new.dropna(how = 'any',inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeab23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain neighborhoods for each fire incident\n",
    "\n",
    "df_new['Neighborhood']=None\n",
    "for index, row in df_new.iterrows():\n",
    "    a=0\n",
    "    point = Point(row['Longitude'],row['Latitude'])\n",
    "    for index1, row1 in df_neighborhoods.iterrows():\n",
    "        if (row1['geometry'].contains(point)):\n",
    "            df_new['Neighborhood'][index]=row1['AREA_NAME']\n",
    "            a=1\n",
    "        if (a==1):\n",
    "            break\n",
    "df_new['Neighborhood'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2142d3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to datetime format\n",
    "\n",
    "df_new['TFS_Alarm_Time'] = pd.to_datetime(df_new['TFS_Alarm_Time'])\n",
    "df_new['TFS_Arrival_Time'] = pd.to_datetime(df_new['TFS_Arrival_Time'], errors = 'coerce')\n",
    "\n",
    "df_new.dropna(how = 'any',inplace = True)\n",
    "#Calculate response time of Fire Stations\n",
    "\n",
    "df_new['Response'] = df_new[\"TFS_Arrival_Time\"]-df_new['TFS_Alarm_Time']\n",
    "\n",
    "response = []\n",
    "for x in df_new['Response']:\n",
    "    time =int(x.total_seconds())\n",
    "    response.append(time)\n",
    "\n",
    "\n",
    "df_new['Response']=response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a47ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polygon geometry to its correct format\n",
    "\n",
    "df_firestation['geometry'] = df_firestation['geometry'].apply(lambda x: shape(json.loads(x)))\n",
    "df_firestation.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803769e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype of column\n",
    "\n",
    "df_new['Incident_Station_Area']=df_new['Incident_Station_Area'].astype(float)\n",
    "\n",
    "# Obtain the fire station name for each fire incident\n",
    "\n",
    "df_new['Fire_Station_Name']=None\n",
    "for index, row in df_new.iterrows():\n",
    "    for index1, row1 in df_firestation.iterrows():\n",
    "        if(row['Incident_Station_Area']==row1['STATION']):\n",
    "            df_new['Fire_Station_Name'][index]=row1['WARD_NAME']\n",
    "\n",
    "df_new['Fire_Station_Name'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d4e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Clean the Neighborhood Dataset\n",
    "\n",
    "df_neighborhoods.drop(columns=['PARENT_AREA_ID','CLASSIFICATION','CLASSIFICATION_CODE', '_id'], inplace = True)\n",
    "df_neighborhoods.sort_values('AREA_NAME', inplace = True)\n",
    "df_neighborhoods['Total_Incidents']=df_new.groupby('Neighborhood')['_id'].count().values\n",
    "gdf = gpd.GeoDataFrame(df_neighborhoods)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "\n",
    "gdf1 = gpd.GeoDataFrame(df_firestation)\n",
    "gdf1.to_file('Fire_Station.geojson', driver='GeoJSON')\n",
    "df_new.to_csv('Fire_Incidents_Data.csv',index = False)\n",
    "gdf.to_file('Neighborhoods.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd5f2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
